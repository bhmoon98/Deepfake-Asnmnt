{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17341,"status":"ok","timestamp":1684126528352,"user":{"displayName":"문보현","userId":"17059632883058912178"},"user_tz":-540},"id":"DHSMpeFLMPTV","outputId":"8a59ec05-3806-4242-ae20-34a1bce61b6a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1684126528353,"user":{"displayName":"문보현","userId":"17059632883058912178"},"user_tz":-540},"id":"NYWu4SJ_MeKv","outputId":"e4dcce89-9ecc-461b-a1d6-fa7906fe7db2"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/Colab Notebooks/Deepfake Asnmnt\n"]}],"source":["cd  drive/MyDrive/Colab Notebooks/'Deepfake Asnmnt'/"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11983,"status":"ok","timestamp":1684126540332,"user":{"displayName":"문보현","userId":"17059632883058912178"},"user_tz":-540},"id":"deSal94BVhai","outputId":"21b775da-f203-4b5f-d8b7-8ad2f8961315"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting timm\n","  Downloading timm-0.9.2-py3-none-any.whl (2.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torch>=1.7 in /usr/local/lib/python3.10/dist-packages (from timm) (2.0.0+cu118)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.15.1+cu118)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0)\n","Collecting huggingface-hub (from timm)\n","  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting safetensors (from timm)\n","  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.12.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7->timm) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7->timm) (16.0.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (2023.4.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (2.27.1)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (4.65.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (23.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (1.22.4)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (8.4.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7->timm) (2.1.2)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (3.4)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7->timm) (1.3.0)\n","Installing collected packages: safetensors, huggingface-hub, timm\n","Successfully installed huggingface-hub-0.14.1 safetensors-0.3.1 timm-0.9.2\n"]}],"source":["!pip install timm"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":12663,"status":"ok","timestamp":1684126552987,"user":{"displayName":"문보현","userId":"17059632883058912178"},"user_tz":-540},"id":"_TbdxpHFNHSS"},"outputs":[],"source":["import timm \n","import os\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import matplotlib.pyplot as plt\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision.transforms import transforms\n","from torch.utils.data import DataLoader\n","from PIL import Image\n","from sklearn.metrics import precision_recall_fscore_support"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":20,"status":"ok","timestamp":1684126552988,"user":{"displayName":"문보현","userId":"17059632883058912178"},"user_tz":-540},"id":"0QZZuaDgMn7u"},"outputs":[],"source":["device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":105,"referenced_widgets":["684d7751d26c498997383b9ab7fdb41e","edfeea5c2d4b472ebc7591793f85576d","fc1c6387ab6b472fbea5deb893dd6436","2c5243fc182c40349e33e6748fd2790f","3b0e78d3a0a04b0a9e8fbe40593c1f1d","c48921f8d4af46f390020a4da5127ae1","fc4abfe2284d4e21917619e7ba3d68d2","9d6b00f85e444d83af24c94d79006ad2","c0b920cc052f4935b12efcd1e8ccae91","e1ba40b85b74441d96393318081c18af","bb4772c367204ac1afd3892c055632de"]},"executionInfo":{"elapsed":2652,"status":"ok","timestamp":1684126555622,"user":{"displayName":"문보현","userId":"17059632883058912178"},"user_tz":-540},"id":"mZ6nOu1lWW8V","outputId":"dc65ef23-d21f-4ded-f519-0b58d1de262c"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/timm/models/_factory.py:114: UserWarning: Mapping deprecated model name xception to current legacy_xception.\n","  model = create_fn(\n","Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-cadene/xception-43020ad28.pth\" to /root/.cache/torch/hub/checkpoints/xception-43020ad28.pth\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"684d7751d26c498997383b9ab7fdb41e","version_major":2,"version_minor":0},"text/plain":["Downloading model.safetensors:   0%|          | 0.00/21.4M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["# num_classes = 2\n","# xc_model = timm.create_model('xception', pretrained = True, num_classes = num_classes).to(device)\n","# ef_model = timm.create_model('efficientnet_b0', pretrained=True, num_classes = num_classes).to(device)\n","\n","# criterion = nn.BCEWithLogitsLoss()\n","# optimizer_xc = optim.Adam(xc_model.parameters(), lr=0.001)\n","# optimizer_ef = optim.Adam(ef_model.parameters(), lr=0.001)\n","\n","# x     = torch.randn(32, 3, 224, 224).to(device) # 32 is batch_size\n","# ef_model(x).shape"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1684126556063,"user":{"displayName":"문보현","userId":"17059632883058912178"},"user_tz":-540},"id":"Nek81guOijFo"},"outputs":[],"source":["class BaseDataset(Dataset):\n","    def __init__(self, data_path):\n","        self.data_path = data_path\n","        self.transforms = transforms.Compose([\n","            transforms.Resize((224, 224)),\n","            transforms.ToTensor(),\n","            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","        ])\n","        \n","        self.imgs = []\n","        self.labels = []\n","        \n","        for file in os.listdir(data_path):\n","            if file.endswith('.png'):\n","                img_path = os.path.join(data_path, file)\n","                label = file.split('_')[0]  # 파일 이름에서 레이블 파싱\n","                self.imgs.append(img_path)\n","                self.labels.append(label)\n","        \n","    def __len__(self):\n","        return len(self.imgs)\n","    \n","    def __getitem__(self, idx):\n","        img = Image.open(self.imgs[idx])\n","        img = self.transforms(img)\n","        label = 1 if self.labels[idx] == 'fake' else 0\n","        return img, label"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1684126556063,"user":{"displayName":"문보현","userId":"17059632883058912178"},"user_tz":-540},"id":"V-bM1v7FhGbS"},"outputs":[],"source":["# Train models\n","class Experiment():\n","    def __init__(self):\n","        self.num_classes = 2\n","        self.xc_model = timm.create_model('xception', pretrained = True, num_classes = self.num_classes).to(device)\n","        self.ef_model = timm.create_model('efficientnet_b0', pretrained=True, num_classes = self.num_classes).to(device)\n","\n","        self.criterion = nn.BCEWithLogitsLoss()\n","        self.optimizer_xc = optim.Adam(self.xc_model.parameters(), lr=0.001)\n","        self.optimizer_ef = optim.Adam(self.ef_model.parameters(), lr=0.001)\n","\n","\n","    def train_model(self, trainloader, valloader):\n","        num_epochs = 100\n","\n","        xc_train_accs = []\n","        xc_val_accs = []\n","        ef_train_accs = []\n","        ef_val_accs = []\n","\n","        for epoch in range(num_epochs):\n","            # Training loop for Xception model\n","            self.xc_model.train()\n","            xc_total_loss = 0\n","            xc_total_correct = 0\n","            for images, labels in trainloader:\n","                images = images.to(device)\n","                labels = labels.to(device)\n","                self.optimizer_xc.zero_grad()\n","                outputs = self.xc_model(images)\n","                labels_onehot = nn.functional.one_hot(labels, num_classes = self.num_classes).float()\n","                loss = self.criterion(outputs, labels_onehot)\n","                loss.backward()\n","                self.optimizer_xc.step()\n","\n","                xc_total_loss += loss.item()\n","                xc_total_correct += (outputs.argmax(dim=1) == labels).sum().item()\n","\n","            xc_train_loss = xc_total_loss / len(trainloader)\n","            xc_train_acc = xc_total_correct / len(trainloader.dataset)\n","            xc_train_accs.append(xc_train_acc)\n","\n","            print(f'Epoch {epoch+1} - Xception model - Training loss: {xc_train_loss:.4f} - Training accuracy: {xc_train_acc:.4f}')\n","\n","            # Training loop for EfficientNet model\n","            self.ef_model.train()\n","            ef_total_loss = 0\n","            ef_total_correct = 0\n","            for images, labels in trainloader:\n","                images = images.to(device)\n","                labels = labels.to(device)\n","                self.optimizer_ef.zero_grad()\n","                outputs = self.ef_model(images)\n","                labels_onehot = nn.functional.one_hot(labels, num_classes=self.num_classes).float()\n","                loss = self.criterion(outputs, labels_onehot)\n","                loss.backward()\n","                self.optimizer_ef.step()\n","\n","                ef_total_loss += loss.item()\n","                ef_total_correct += (outputs.argmax(dim=1) == labels).sum().item()\n","\n","            ef_train_loss = ef_total_loss / len(trainloader)\n","            ef_train_acc = ef_total_correct / len(trainloader.dataset)\n","            ef_train_accs.append(ef_train_acc)\n","\n","            print(f'Epoch {epoch+1} - EfficientNet model - Training loss: {ef_train_loss:.4f} - Training accuracy: {ef_train_acc:.4f}')\n","\n","\n","            # Validation loop\n","            self.xc_model.eval()\n","            self.ef_model.eval()\n","            with torch.no_grad():\n","                xc_total, xc_correct = 0, 0\n","                for images, labels in valloader:\n","                    images = images.to(device)\n","                    labels = labels.to(device)\n","                    outputs = self.xc_model(images)\n","                    _, predicted = torch.max(outputs.data, 1)\n","                    xc_total += labels.size(0)\n","                    xc_correct += (predicted == labels).sum().item()\n","                xc_accuracy = xc_correct / xc_total\n","                xc_val_accs.append(xc_accuracy)\n","            \n","                print(f'Epoch {epoch+1} - Xception model - Validation accuracy: {xc_accuracy:.4f}')\n","\n","                ef_total, ef_correct = 0, 0\n","                for images, labels in valloader:\n","                    images = images.to(device)\n","                    labels = labels.to(device)\n","                    outputs = self.ef_model(images)\n","                    _, predicted = torch.max(outputs.data, 1)\n","                    ef_total += labels.size(0)\n","                    ef_correct += (predicted == labels).sum().item()\n","                ef_accuracy = ef_correct / ef_total\n","                ef_val_accs.append(ef_accuracy)\n","\n","                print(f'Epoch {epoch+1} - EfficientNet model - Validation accuracy: {ef_accuracy:.4f}')\n","\n","        plt.plot(xc_train_accs, label='Xception Training Accuracy')\n","        plt.plot(xc_val_accs, label='Xception Validation Accuracy')\n","        plt.plot(ef_train_accs, label='EfficientNet Training Accuracy')\n","        plt.plot(ef_val_accs, label='EfficientNet Validation Accuracy')\n","        plt.legend()\n","        plt.xlabel('Epoch')\n","        plt.ylabel('Accuracy')\n","        plt.show()\n","\n","    def test_model(self, testloader):\n","\n","        self.xc_model.eval()\n","        self.ef_model.eval()\n","        with torch.no_grad():\n","            xc_total, xc_correct = 0, 0\n","            xc_true_labels, xc_predicted_labels = [], []\n","            for images, labels in testloader:\n","                images = images.to(device)\n","                labels = labels.to(device)\n","                outputs = self.xc_model(images)\n","                _, predicted = torch.max(outputs.data, 1)\n","                xc_total += labels.size(0)\n","                xc_correct += (predicted == labels).sum().item()\n","                xc_true_labels += labels.cpu().tolist()\n","                xc_predicted_labels += predicted.cpu().tolist()\n","            xc_accuracy = xc_correct / xc_total\n","            xc_precision, xc_recall, xc_f1, _ = precision_recall_fscore_support(xc_true_labels, xc_predicted_labels, average='binary')\n","        \n","            print(f'Xception model - Test accuracy: {xc_accuracy:.4f}')\n","            print(f'Xception model - Test precision: {xc_precision:.4f}')\n","            print(f'Xception model - Test recall: {xc_recall:.4f}')\n","            print(f'Xception model - Test F1 score: {xc_f1:.4f}')\n","\n","\n","            ef_total, ef_correct = 0, 0\n","            ef_true_labels, ef_predicted_labels = [], []\n","            for images, labels in testloader:\n","                images = images.to(device)\n","                labels = labels.to(device)\n","                outputs = self.ef_model(images)\n","                _, predicted = torch.max(outputs.data, 1)\n","                ef_total += labels.size(0)\n","                ef_correct += (predicted == labels).sum().item()\n","                ef_true_labels += labels.cpu().tolist()\n","                ef_predicted_labels += predicted.cpu().tolist()\n","            ef_accuracy = ef_correct / ef_total\n","            ef_precision, ef_recall, ef_f1, _ = precision_recall_fscore_support(ef_true_labels, ef_predicted_labels, average='binary')\n","\n","            print(f'EfficientNet model - Test accuracy: {ef_accuracy:.4f}')\n","            print(f'EfficientNet model - Test precision: {ef_precision:.4f}')\n","            print(f'EfficientNet model - Test recall: {ef_recall:.4f}')\n","            print(f'EfficientNet model - Test F1 score: {ef_f1:.4f}')"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":235263,"status":"ok","timestamp":1684126791321,"user":{"displayName":"문보현","userId":"17059632883058912178"},"user_tz":-540},"id":"ZEka6VQlWX__","outputId":"67f055dd-7b91-441e-9c22-8f362b5247cd"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"name":"stdout","output_type":"stream","text":["Xception model - Test accuracy: 0.5000\n","Xception model - Test precision: 0.2500\n","Xception model - Test recall: 0.5000\n","Xception model - Test F1 score: 0.3333\n","EfficientNet model - Test accuracy: 0.5025\n","EfficientNet model - Test precision: 0.5015\n","EfficientNet model - Test recall: 0.8141\n","EfficientNet model - Test F1 score: 0.6207\n"]}],"source":["#1) HighQuality-Face2Face\n","\n","hf_train_dataset = BaseDataset(data_path = \"High Quality/f2f_data/train\")\n","hf_trainloader = DataLoader(hf_train_dataset, batch_size=32, shuffle=True)\n","hf_val_dataset = BaseDataset(data_path = \"High Quality/f2f_data/val\")\n","hf_valloader = DataLoader(hf_val_dataset, batch_size=32, shuffle=True)\n","hf_test_dataset = BaseDataset(data_path = \"High Quality/f2f_data/test\")\n","hf_testloader = DataLoader(hf_test_dataset, batch_size=32, shuffle=True)\n","\n","hf = Experiment()\n","hf.train_model(hf_trainloader, hf_valloader)\n","hf.test_model(hf_testloader)"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":381},"executionInfo":{"elapsed":7156,"status":"error","timestamp":1684126798463,"user":{"displayName":"문보현","userId":"17059632883058912178"},"user_tz":-540},"id":"CdBRsk3R9wQf","outputId":"3901c9e4-e017-4b34-c500-23d6c251792a"},"outputs":[{"ename":"KeyboardInterrupt","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-da4ddfc5d7c0>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#2) HighQuality-NeuralTexture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mhn_train_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBaseDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"High Quality/nt_data/train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mhn_trainloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhn_train_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mhn_val_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBaseDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"High Quality/nt_data/val\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-7-4e2d754d4c4e>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data_path)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                 \u001b[0mimg_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["#2) HighQuality-NeuralTexture\n","\n","hn_train_dataset = BaseDataset(data_path = \"High Quality/nt_data/train\")\n","hn_trainloader = DataLoader(hn_train_dataset, batch_size=32, shuffle=True)\n","hn_val_dataset = BaseDataset(data_path = \"High Quality/nt_data/val\")\n","hn_valloader = DataLoader(hn_val_dataset, batch_size=32, shuffle=True)\n","hn_test_dataset = BaseDataset(data_path = \"High Quality/nt_data/test\")\n","hn_testloader = DataLoader(hn_test_dataset, batch_size=32, shuffle=True)\n","\n","hn = Experiment()\n","hn.train_model(hn_trainloader, hn_valloader)\n","hn.test_model(hn_testloader)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4,"status":"aborted","timestamp":1684126798465,"user":{"displayName":"문보현","userId":"17059632883058912178"},"user_tz":-540},"id":"ewcP7li5CVCb"},"outputs":[],"source":["#3) LowQuality-Face2Face\n","\n","lf_train_dataset = BaseDataset(data_path = \"Low Quality/f2f_data/train\")\n","lf_trainloader = DataLoader(lf_train_dataset, batch_size=32, shuffle=True)\n","lf_val_dataset = BaseDataset(data_path = \"Low Quality/f2f_data/val\")\n","lf_valloader = DataLoader(lf_val_dataset, batch_size=32, shuffle=True)\n","lf_test_dataset = BaseDataset(data_path = \"Low Quality/f2f_data/test\")\n","lf_testloader = DataLoader(lf_test_dataset, batch_size=32, shuffle=True)\n","\n","lf = Experiment()\n","lf.train_model(lf_trainloader, lf_valloader)\n","lf.test_model(lf_testloader)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4,"status":"aborted","timestamp":1684126798465,"user":{"displayName":"문보현","userId":"17059632883058912178"},"user_tz":-540},"id":"4ecbU6eXCn9M"},"outputs":[],"source":["#4) LowQuality-NeuralTexture\n","\n","ln_train_dataset = BaseDataset(data_path = \"Low Quality/nt_data/train\")\n","ln_trainloader = DataLoader(ln_train_dataset, batch_size=32, shuffle=True)\n","ln_val_dataset = BaseDataset(data_path = \"Low Quality/nt_data/val\")\n","ln_valloader = DataLoader(ln_val_dataset, batch_size=32, shuffle=True)\n","ln_test_dataset = BaseDataset(data_path = \"Low Quality/nt_data/test\")\n","ln_testloader = DataLoader(ln_test_dataset, batch_size=32, shuffle=True)\n","\n","ln = Experiment()\n","ln.train_model(ln_trainloader, ln_valloader)\n","ln.test_model(ln_testloader)"]}],"metadata":{"colab":{"gpuType":"T4","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.11"},"widgets":{"application/vnd.jupyter.widget-state+json":{"2c5243fc182c40349e33e6748fd2790f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e1ba40b85b74441d96393318081c18af","placeholder":"​","style":"IPY_MODEL_bb4772c367204ac1afd3892c055632de","value":" 21.4M/21.4M [00:00&lt;00:00, 45.6MB/s]"}},"3b0e78d3a0a04b0a9e8fbe40593c1f1d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"684d7751d26c498997383b9ab7fdb41e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_edfeea5c2d4b472ebc7591793f85576d","IPY_MODEL_fc1c6387ab6b472fbea5deb893dd6436","IPY_MODEL_2c5243fc182c40349e33e6748fd2790f"],"layout":"IPY_MODEL_3b0e78d3a0a04b0a9e8fbe40593c1f1d"}},"9d6b00f85e444d83af24c94d79006ad2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bb4772c367204ac1afd3892c055632de":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c0b920cc052f4935b12efcd1e8ccae91":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c48921f8d4af46f390020a4da5127ae1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e1ba40b85b74441d96393318081c18af":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"edfeea5c2d4b472ebc7591793f85576d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c48921f8d4af46f390020a4da5127ae1","placeholder":"​","style":"IPY_MODEL_fc4abfe2284d4e21917619e7ba3d68d2","value":"Downloading model.safetensors: 100%"}},"fc1c6387ab6b472fbea5deb893dd6436":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9d6b00f85e444d83af24c94d79006ad2","max":21355344,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c0b920cc052f4935b12efcd1e8ccae91","value":21355344}},"fc4abfe2284d4e21917619e7ba3d68d2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}
